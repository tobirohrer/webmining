{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdbcli import dbapi\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = dbapi.connect('18.202.247.58', 39015, 'SYSTEM', 'Glorp2018!')\n",
    "connection.isconnected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 2 mit SQL\n",
    "## Aufgaben 1\n",
    "### SQL View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-View\n",
    "sql_drop_view = 'drop view COUNT_NOUNS_NHTSA'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouns per document\n",
    "sql = 'create view COUNT_NOUNS_NHTSA as select CMPLID, TA_TOKEN, count(*) as COUNT from \"$TA_CDESCRIND\" where TA_TYPE=\\'noun\\' group by CMPLID, TA_TOKEN'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nouns per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nouns(nouns_df):\n",
    "    ax = sns.distplot(nouns_df['count'])\n",
    "    ax.set(xlabel='#nouns per document')\n",
    "    ax.set_title('Nouns per document')\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig('plots/nouns_per_document_NHTSA.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using SQL-View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouns for all documents\n",
    "cursor.execute('select CMPLID, sum(COUNT) from COUNT_NOUNS_NHTSA group by CMPLID order by sum(COUNT) desc')\n",
    "nouns_list = cursor.fetchall()\n",
    "nouns_df = pd.DataFrame(nouns_list)\n",
    "nouns_df.columns = ['doc', 'count']\n",
    "nouns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nouns(nouns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouns for a specific document\n",
    "cursor.execute('select * from COUNT_NOUNS_NHTSA')\n",
    "nouns_list = cursor.fetchall()\n",
    "nouns_df = pd.DataFrame(nouns_list)\n",
    "nouns_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben 2\n",
    "### Size of Lexica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select count(distinct TA_TOKEN) from \"$TA_CDESCRIND\"')\n",
    "nouns_list = cursor.fetchall()\n",
    "lexica_size = pd.DataFrame(nouns_list)\n",
    "lexica_size.columns = ['size']\n",
    "lexica_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of Lexica without punctuation and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    nltk.download('stopwords')\n",
    "    german_stopwords = set(stopwords.words('english'))\n",
    "    data['TOKEN_LOW'] = data['TOKEN'].map(lambda row: str(row).lower())\n",
    "    filtered = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row.TOKEN_LOW not in german_stopwords:\n",
    "            filtered.append(row.TOKEN_LOW)\n",
    "    filtered_lexica = pd.DataFrame(filtered)\n",
    "    filtered_lexica.columns = ['TOKEN']\n",
    "    return filtered_lexica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select distinct TA_TOKEN from \"$TA_CDESCRIND\" where TA_TYPE <> \\'punctuation\\' and TA_TYPE <> \\'number\\'')\n",
    "lexica_list = cursor.fetchall()\n",
    "lexica_df = pd.DataFrame(lexica_list)\n",
    "lexica_df.columns = ['TOKEN']\n",
    "lexica_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_lexica = remove_stopwords(lexica_df)\n",
    "filtered_lexica.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean length of a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouns per document\n",
    "sql = 'create view COUNT_TOKEN_NHTSA as select CMPLID, count(*) as COUNT from \"$TA_CDESCRIND\" group by CMPLID order by count(*) desc'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-View\n",
    "sql_drop_view = 'drop view COUNT_TOKEN_NHTSA'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select avg(COUNT) from COUNT_TOKEN_NHTSA')\n",
    "mean_length_doc = cursor.fetchall()\n",
    "mean_length_doc = pd.DataFrame(mean_length_doc)\n",
    "mean_length_doc.columns = ['AVERAGE']\n",
    "mean_length_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean length of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select AVG(TA_SENTENCE) as AVG_SENTENCE from \"$TA_CDESCRIND\" order by AVG(TA_SENTENCE) desc')\n",
    "mean_length_sentence = cursor.fetchall()\n",
    "mean_length_sentence_df = pd.DataFrame(mean_length_sentence)\n",
    "mean_length_sentence_df_new = mean_length_sentence_df.dropna()\n",
    "mean_length_sentence_df_new.columns = ['AVERAGE']\n",
    "mean_length_sentence_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben 3\n",
    "### Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select TA_TOKEN, count(*) from \"$TA_CDESCRIND\" group by TA_TOKEN order by count(*) desc')\n",
    "words_list = cursor.fetchall()\n",
    "words_df = pd.DataFrame(words_list)\n",
    "words_df.columns = ['TOKEN', 'count']\n",
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with filtered_lexica (removed punctuation and number)\n",
    "cursor.execute('select TA_TOKEN, count(*) from \"$TA_CDESCRIND\" where TA_TYPE <> \\'punctuation\\' and TA_TYPE <> \\'number\\' group by TA_TOKEN order by count(*) desc')\n",
    "lexica_list = cursor.fetchall()\n",
    "lexica_df = pd.DataFrame(lexica_list)\n",
    "lexica_df.columns = ['TOKEN', 'count']\n",
    "lexica_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequent and rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent words\n",
    "cursor.execute('select TA_TOKEN, count(*) from \"$TA_CDESCRIND\" where TA_TYPE = \\'noun\\' or TA_TYPE = \\'verb\\' or TA_TYPE = \\'adjective\\' group by TA_TOKEN order by count(*) desc')\n",
    "words_list = cursor.fetchall()\n",
    "words_df = pd.DataFrame(words_list)\n",
    "words_df.columns = ['TA_TOKEN', 'count']\n",
    "sns.set(rc={'figure.figsize':(27,7)})\n",
    "ax = sns.barplot(x=\"TA_TOKEN\", y=\"count\", data=words_df.head(20))\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('plots/barplot_words_freq_NHTSA.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rare words\n",
    "words_df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restriction to POS-Tags, categories or documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restriction to nouns\n",
    "# barplot\n",
    "cursor.execute('select top 20 TA_TOKEN, count(*) from \"$TA_CDESCRIND\" where TA_TYPE=\\'noun\\' group by TA_TOKEN order by count(*) desc')\n",
    "results_words = cursor.fetchall()\n",
    "results_words_df = pd.DataFrame(results_words)\n",
    "results_words_df.columns = ['TA_TOKEN', 'count']\n",
    "sns.set(rc={'figure.figsize':(27,7)})\n",
    "ax = sns.barplot(x=\"TA_TOKEN\", y=\"count\", data=results_words_df)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('plots/barplot_nouns_NHTSA.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud \n",
    "import matplotlib.pyplot as plt\n",
    "tmpDict = {}\n",
    "cursor.execute('SELECT top 20 TA_TOKEN, count(*) from \"$TA_CDESCRIND\" where TA_TYPE=\\'noun\\' group by TA_TOKEN order by count(*) desc')\n",
    "for row in cursor: \n",
    "    tmpDict[row[0]]=row[1]\n",
    "wordcloud = WordCloud(width=480, height=480, margin=0).generate_from_frequencies(tmpDict) \n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.margins(x=0, y=0)\n",
    "plt.show()\n",
    "wordcloud.to_file('plots/wordcloud_nouns_NHTSA.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ambiguity of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create view\n",
    "cursor.execute('create view POSTAGS_NHTSA as select TA_NORMALIZED as nor, CMPLID as id, TA_TYPE as type, count(*) as count_words from \"$TA_CDESCRIND\" where TA_TYPE = \\'noun\\' or TA_TYPE = \\'verb\\' or TA_TYPE = \\'adjective\\' group by TA_NORMALIZED, CMPLID, TA_TYPE having count(*)>1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-View\n",
    "sql_drop_view = 'drop view POSTAGS_NHTSA'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select NOR, ID, count(NOR) from POSTAGS_NHTSA group by NOR, ID having count(NOR) > 1')\n",
    "words_list = cursor.fetchall()\n",
    "words_df = pd.DataFrame(words_list)\n",
    "df = words_df.dropna()\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben 5\n",
    "### 1. Statistics\n",
    "#### The distribution of top part-of-speech tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk as nltk\n",
    "\n",
    "cursor.execute('select CDESCR from \"CMPL100K\" where CMPLID = \\'112392\\'')\n",
    "token_results = cursor.fetchall()\n",
    "token_results\n",
    "token_results_df = pd.DataFrame(token_results)\n",
    "token_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_results_df.columns = ['CDESCR']\n",
    "\n",
    "blob = TextBlob(str(token_results_df['CDESCR']))\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#TODO\n",
    "from chart_studio.plotly import iplot\n",
    "pos_df = pd.DataFrame(blob.tags, columns = ['word' , 'pos'])\n",
    "pos_df\n",
    "pos_df = pos_df['pos'].value_counts()[:10]\n",
    "#.loc[:, ['pos']])\n",
    "pos_df = pd.DataFrame(pos_df)\n",
    "pos_df.iplot(\n",
    "    kind='bar',\n",
    "    xTitle='POS',\n",
    "    yTitle='count', \n",
    "    title='Top 20 Part-of-speech tagging for review corpus')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
