{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdbcli import dbapi\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = dbapi.connect('18.202.26.190', 39015, 'SYSTEM', 'Glorp2018!')\n",
    "connection.isconnected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 1 - Import t3n data into HANA\n",
    "## Aufgaben 1/ 2 / 3/ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "t3n_data = pd.read_csv('../praktikum1/t3n_data_spider.csv', encoding='utf8')\n",
    "t3n_df = t3n_data.dropna()\n",
    "t3n_df = t3n_df.replace('\\n','', regex=True)\n",
    "t3n_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop table\n",
    "sql = 'DROP TABLE T3N'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table():\n",
    "    sql = 'CREATE COLUMN TABLE \\\"SYSTEM\\\".\\\"T3N\\\" (\\\"ID\\\" VARCHAR(500),\\\"HEADING\\\" VARCHAR(2000),\\\"CATEGORY\\\" VARCHAR(2000),\\\"TEASER\\\" VARCHAR(5000),\\\"TEXT\\\" CLOB MEMORY THRESHOLD 1000,\\\"URL\\\" VARCHAR(2000), PRIMARY KEY (\\\"ID\\\"))'\n",
    "    cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_escaped_string(string):\n",
    "    return '\\'' + str(string) + '\\''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data():\n",
    "    for index, row in t3n_df.iterrows():\n",
    "        sql_insert_datapoint = 'insert into \\\"SYSTEM\\\".\\\"T3N\\\" (ID, HEADING, CATEGORY, TEASER, TEXT, URL) VALUES (' + get_escaped_string(row['id']) + ', ' + get_escaped_string(row['heading']) +', ' + get_escaped_string(row['category']) + ',' + get_escaped_string(row['teaser']) + ', ' + get_escaped_string(row['text']) + ', ' + get_escaped_string(row['url'])+ ')'\n",
    "        print(sql_insert_datapoint)\n",
    "        #print(row['heading'])\n",
    "        cursor.execute(sql_insert_datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table()\n",
    "insert_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben 5/ 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION 'LINGANALYSIS_BASIC'\n",
    "sql = 'CREATE FULLTEXT INDEX \"T3NTEXTIND\" ON \"SYSTEM\".\"T3N\" (\"TEXT\") CONFIGURATION \\'LINGANALYSIS_BASIC\\' ASYNC LANGUAGE DETECTION (\\'de\\', \\'en\\') TEXT ANALYSIS ON'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION 'LINGANALYSIS_STEMS'\n",
    "sql = 'CREATE FULLTEXT INDEX \"T3NTEXTIND\" ON \"SYSTEM\".\"T3N\" (\"TEXT\") CONFIGURATION \\'LINGANALYSIS_STEMS\\' ASYNC LANGUAGE DETECTION (\\'de\\', \\'en\\') TEXT ANALYSIS ON'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION 'LINGANALYSIS_FULL' \n",
    "sql = 'CREATE FULLTEXT INDEX \"T3NTEXTIND\" ON \"SYSTEM\".\"T3N\" (\"TEXT\") CONFIGURATION \\'LINGANALYSIS_FULL\\' ASYNC LANGUAGE DETECTION (\\'de\\', \\'en\\') TEXT ANALYSIS ON'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop index\n",
    "sql = 'DROP FULLTEXT INDEX \"T3NTEXTIND\";'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 2 mit SQL\n",
    "## Aufgabe 1\n",
    "### SQL-View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-View\n",
    "sql_drop_view = 'drop view COUNT_NOUNS'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouns per document\n",
    "sql = 'create view COUNT_NOUNS as select ID, TA_TOKEN, count(*) as COUNT from \"$TA_T3NTEXTIND\" where TA_TYPE=\\'noun\\' group by ID, TA_TOKEN'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nouns per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nouns(nouns_df):\n",
    "    ax = sns.distplot(nouns_df['count'])\n",
    "    ax.set(xlabel='#nouns per document')\n",
    "    ax.set_title('Nouns per document')\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig('plots/nouns_per_document_t3n.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using SQL-View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouns for all documents\n",
    "cursor.execute('select ID, sum(COUNT) from COUNT_NOUNS group by ID order by sum(COUNT) desc')\n",
    "nouns_list = cursor.fetchall()\n",
    "nouns_df = pd.DataFrame(nouns_list)\n",
    "nouns_df.columns = ['doc', 'count']\n",
    "nouns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nouns(nouns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouns for a specific document\n",
    "cursor.execute('select * from COUNT_NOUNS')\n",
    "nouns_list = cursor.fetchall()\n",
    "nouns_df = pd.DataFrame(nouns_list)\n",
    "nouns_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without SQL-View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouns for all documents\n",
    "cursor.execute('select ID, count(*) from \"$TA_T3NTEXTIND\" where TA_TYPE=\\'noun\\' group by ID order by count(*) desc')\n",
    "nouns_list = cursor.fetchall()\n",
    "nouns_df = pd.DataFrame(nouns_list)\n",
    "nouns_df.columns = ['doc', 'count']\n",
    "nouns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nouns(nouns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouns for a specific document\n",
    "cursor.execute('select ID, TA_TOKEN, count(*) from \"$TA_T3NTEXTIND\" where TA_TYPE=\\'noun\\' group by ID, TA_TOKEN')\n",
    "nouns_list = cursor.fetchall()\n",
    "nouns_df = pd.DataFrame(nouns_list)\n",
    "nouns_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2\n",
    "### Size of Lexica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select count(distinct TA_TOKEN) from \"$TA_T3NTEXTIND\"')\n",
    "nouns_list = cursor.fetchall()\n",
    "lexica_size = pd.DataFrame(nouns_list)\n",
    "lexica_size.columns = ['size']\n",
    "lexica_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of Lexica without punctuation and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    nltk.download('stopwords')\n",
    "    german_stopwords = set(stopwords.words('german'))\n",
    "    data['TOKEN_LOW'] = data['TOKEN'].map(lambda row: str(row).lower())\n",
    "    filtered = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row.TOKEN_LOW not in german_stopwords:\n",
    "            filtered.append(row.TOKEN_LOW)\n",
    "    filtered_lexica = pd.DataFrame(filtered)\n",
    "    filtered_lexica.columns = ['TOKEN']\n",
    "    return filtered_lexica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select distinct TA_TOKEN from \"$TA_T3NTEXTIND\" where TA_TYPE <> \\'punctuation\\' and TA_TYPE <> \\'number\\'')\n",
    "lexica_list = cursor.fetchall()\n",
    "lexica_df = pd.DataFrame(lexica_list)\n",
    "lexica_df.columns = ['TOKEN']\n",
    "lexica_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_lexica = remove_stopwords(lexica_df)\n",
    "filtered_lexica.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean length of a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouns per document\n",
    "sql = 'create view COUNT_TOKEN as select ID, count(*) as COUNT from \"$TA_T3NTEXTIND\" group by ID order by count(*) desc'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-View\n",
    "sql_drop_view = 'drop view COUNT_TOKEN'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select avg(COUNT) from COUNT_TOKEN')\n",
    "mean_length_doc = cursor.fetchall()\n",
    "mean_length_doc = pd.DataFrame(mean_length_doc)\n",
    "mean_length_doc.columns = ['AVERAGE']\n",
    "mean_length_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean length of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select AVG(TA_SENTENCE) as AVG_SENTENCE from \"$TA_T3NTEXTIND\" order by AVG(TA_SENTENCE) desc')\n",
    "mean_length_sentence = cursor.fetchall()\n",
    "mean_length_sentence_df = pd.DataFrame(mean_length_sentence)\n",
    "mean_length_sentence_df_new = mean_length_sentence_df.dropna()\n",
    "mean_length_sentence_df_new.columns = ['AVERAGE']\n",
    "mean_length_sentence_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3\n",
    "### Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select TA_TOKEN, count(*) from \"$TA_T3NTEXTIND\" group by TA_TOKEN order by count(*) desc')\n",
    "words_list = cursor.fetchall()\n",
    "words_df = pd.DataFrame(words_list)\n",
    "words_df.columns = ['TOKEN', 'count']\n",
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with filtered_lexica\n",
    "cursor.execute('select TA_TOKEN, count(*) from \"$TA_T3NTEXTIND\" where TA_TYPE <> \\'punctuation\\' and TA_TYPE <> \\'number\\' group by TA_TOKEN order by count(*) desc')\n",
    "lexica_list = cursor.fetchall()\n",
    "lexica_df = pd.DataFrame(lexica_list)\n",
    "lexica_df.columns = ['TOKEN', 'count']\n",
    "lexica_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequent and rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent words\n",
    "cursor.execute('select TA_TOKEN, count(*) from \"$TA_T3NTEXTIND\" group by TA_TOKEN order by count(*) desc')\n",
    "words_list = cursor.fetchall()\n",
    "words_df = pd.DataFrame(words_list)\n",
    "words_df.columns = ['TA_TOKEN', 'count']\n",
    "sns.set(rc={'figure.figsize':(27,7)})\n",
    "sns.barplot(x=\"TA_TOKEN\", y=\"count\", data=words_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rare words\n",
    "words_df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restriction to POS-Tags, categories or documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restriction to nouns\n",
    "# barplot\n",
    "cursor.execute('select top 20 TA_TOKEN, count(*) from \"$TA_T3NTEXTIND\" where TA_TYPE=\\'noun\\' group by TA_TOKEN order by count(*) desc')\n",
    "results_words = cursor.fetchall()\n",
    "results_words_df = pd.DataFrame(results_words)\n",
    "results_words_df.columns = ['TA_TOKEN', 'count']\n",
    "sns.set(rc={'figure.figsize':(27,7)})\n",
    "ax = sns.barplot(x=\"TA_TOKEN\", y=\"count\", data=results_words_df)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('plots/barplot_nouns_t3n.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud \n",
    "import matplotlib.pyplot as plt\n",
    "tmpDict = {}\n",
    "cursor.execute('SELECT top 20 TA_TOKEN, count(*) from \"$TA_T3NTEXTIND\" where TA_TYPE=\\'noun\\' group by TA_TOKEN order by count(*) desc')\n",
    "for row in cursor: \n",
    "    tmpDict[row[0]]=row[1]\n",
    "wordcloud = WordCloud(width=480, height=480, margin=0).generate_from_frequencies(tmpDict) \n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.margins(x=0, y=0)\n",
    "plt.show()\n",
    "wordcloud.to_file('plots/wordcloud_nouns_t3n.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restriction to category\n",
    "# frequent words of category Marketing\n",
    "cursor.execute('select top 20 TA_TOKEN, count(*) from \"$TA_T3NTEXTIND\", \"T3N\" where \"$TA_T3NTEXTIND\".ID = \"T3N\".ID and \"T3N\".CATEGORY = \\'Marketing\\' group by TA_TOKEN order by count(*) desc')\n",
    "words_list = cursor.fetchall()\n",
    "results_words_df = pd.DataFrame(words_list)\n",
    "results_words_df.columns = ['TA_TOKEN', 'count']\n",
    "sns.set(rc={'figure.figsize':(27,7)})\n",
    "sns.barplot(x=\"TA_TOKEN\", y=\"count\", data=results_words_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ambiguity of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('create view POSTAGS as select TA_NORMALIZED as nor, ID as id, TA_TYPE as type, count(*) as count_words from \"$TA_T3NTEXTIND\" group by TA_NORMALIZED, ID, TA_TYPE having count(*)>1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select NOR, ID, count(NOR) from POSTAGS group by NOR, ID having count(NOR) > 1')\n",
    "words_list = cursor.fetchall()\n",
    "words_df = pd.DataFrame(words_list)\n",
    "df = words_df.dropna()\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT top 10 TA_TOKEN, count(*) from \"$TA_T3NTEXTIND\" where TA_TYPE=\\'noun\\' group by TA_TOKEN order by count(*) desc')\n",
    "words_top_20 = cursor.fetchall()\n",
    "words_top_20_df = pd.DataFrame(words_top_20)\n",
    "#words_top_20_df = words_top_20_df.dropna()\n",
    "words_top_20_df.columns = ['noun', 'count']\n",
    "words_top_20_df.head(20)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(17,7)})\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"noun\", y=\"count\", data=words_top_20_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT category from T3N')\n",
    "category_t3n = cursor.fetchall()\n",
    "category_t3n_df = pd.DataFrame(category_t3n)\n",
    "category_t3n_df.columns = ['category']\n",
    "sns.set(rc={'figure.figsize':(27,7)})\n",
    "ax = sns.countplot(x=\"category\", data=category_t3n_df)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('plots/categories_countplot_t3n.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO sentiment analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
