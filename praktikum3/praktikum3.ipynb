{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hdbcli import dbapi\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "connection = dbapi.connect('<ip-address>', 39015, 'SYSTEM', '<password>')\n",
    "connection.isconnected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ermitteln Sie die häufigsten Folgen von Adjektiv-Nomen Bigrammen im Corpus (Hinweis: wenn Sie mit SQL arbeiten, können Sie einen non-equi auto-join verwenden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = 'select top 10 t1.TA_TOKEN, t2.TA_TOKEN, count(*) from \"SYSTEM\".\"$TA_CDESCRIND\" as t1, \"SYSTEM\".\"$TA_CDESCRIND\" as t2 where t1.cmplid=t2.cmplid and t1.TA_COUNTER=t2.TA_COUNTER-1 and t1.TA_SENTENCE=t2.TA_SENTENCE and t1.TA_TYPE=\\'adjective\\' and t2.TA_TYPE=\\'noun\\' group by t1.TA_TOKEN, t2.TA_TOKEN order by count(*) desc'\n",
    "cursor.execute(sql)\n",
    "adjective_noun = cursor.fetchall()\n",
    "adjective_noun_df = pd.DataFrame(adjective_noun)\n",
    "adjective_noun_df.columns = ['adjective', 'noun', 'count']\n",
    "adjective_noun_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ermitteln Sie die häufigsten Co-occurrences von Adjektiven innerhalb eines Satzes (Position egal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select top 10 t1.TA_TOKEN as adjective, t2.TA_TOKEN as adjective2, count(*) from \"SYSTEM\".\"$TA_CDESCRIND\" as t1, \"SYSTEM\".\"$TA_CDESCRIND\" as t2 where t1.cmplid=t2.cmplid and t1.TA_COUNTER<t2.TA_COUNTER and t1.TA_SENTENCE=t2.TA_SENTENCE and t1.TA_TYPE=\\'adjective\\' and t2.TA_TYPE=\\'adjective\\' group by t1.TA_TOKEN, t2.TA_TOKEN order by count(*) desc'\n",
    "cursor.execute(sql)\n",
    "adj_adj = cursor.fetchall()\n",
    "adj_adj_df = pd.DataFrame(adj_adj)\n",
    "adj_adj_df.columns = ['adjective', 'adjective 2', 'count']\n",
    "adj_adj_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Berechnen Sie die top-3 tf-idf (ntn nach der SMART Notation) Werte von Nomen im Corpus. Schauen Sie sich die entsprechenden Dokumente und die jeweiligen tf bzw. idf Wertkomponenten an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL-View MAX_FREQ_NOUN\n",
    "sql = 'create view MAX_FREQ_NOUN as select CMPLID as CMPLID, TA_TOKEN as noun, count(*) as tf from \"$TA_CDESCRIND\" where TA_TYPE=\\'noun\\' group by CMPLID, TA_TOKEN order by count(*) desc'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-View MAX_FREQ_NOUN\n",
    "sql_drop_view = 'drop view MAX_FREQ_NOUN'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf\n",
    "sql = 'select top 3 CMPLID, noun, tf from MAX_FREQ_NOUN'\n",
    "cursor.execute(sql)\n",
    "tf = cursor.fetchall()\n",
    "tf_df = pd.DataFrame(tf)\n",
    "tf_df.columns = ['CMPLID','noun', 'tf']\n",
    "tf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL-View COUNT_DOCS\n",
    "sql = 'create view COUNT_DOCS as select count(DISTINCT cmplid) as n_total from \"SYSTEM\".\"$TA_CDESCRIND\"'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL-View VALUES_DF\n",
    "sql = 'create view VALUES_DF as select TA_TOKEN as noun, count(DISTINCT CMPLID) as DF from \"$TA_CDESCRIND\" where TA_TYPE=\\'noun\\' group by TA_TOKEN'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL-View VALUES_IDF\n",
    "sql = 'create view VALUES_IDF as select t1.noun, ln((t2.n_total/t1.DF)) as idf from VALUES_DF as t1, COUNT_DOCS as t2 order by idf desc' \n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-Views\n",
    "sql_drop_view = 'drop view VALUES_IDF'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idf\n",
    "sql = 'select top 3 * from VALUES_IDF'\n",
    "cursor.execute(sql)\n",
    "idf = cursor.fetchall()\n",
    "idf_df = pd.DataFrame(idf)\n",
    "idf_df.columns = ['noun', 'idf']\n",
    "idf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select top 3 t2.CMPLID, t1.noun, t2.tf, t1.idf, (t2.tf*t1.idf) as tfidf from VALUES_IDF as t1, MAX_FREQ_NOUN as t2 where t1.noun = t2.noun order by tfidf desc'\n",
    "cursor.execute(sql)\n",
    "idf = cursor.fetchall()\n",
    "idf_df = pd.DataFrame(idf)\n",
    "idf_df.columns = ['CMPLID', 'noun','tf', 'idf', 'tfidf']\n",
    "idf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Berücksichtigen Sie nur Adjektiv-Nomen Bigramme in Dokumenten mit der ID<1000000. Ermitteln Sie anhand des Chi2 Tests die 3 statistisch signifikantesten und die 3 am wenigsten signifikant zusammenhängenden Bigramme mit w1=* (beliebig) und w2=Tire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create view\n",
    "# all adjective-noun bigrams with ID < 1000000 and w1=* and w2=Tire\n",
    "sql = 'create view adjective_noun_bigram as select t1.TA_TOKEN as adjective, t2.TA_TOKEN as noun, count(*) as  w1_and_w2 from \"SYSTEM\".\"$TA_CDESCRIND\" as t1, \"SYSTEM\".\"$TA_CDESCRIND\" as t2 where t1.cmplid=t2.cmplid and t1.TA_COUNTER=t2.TA_COUNTER-1 and t1.TA_SENTENCE=t2.TA_SENTENCE and t1.TA_TYPE=\\'adjective\\' and t2.TA_TYPE=\\'noun\\' and t1.cmplid<1000000 and t2.TA_TOKEN=\\'TIRE\\' group by t1.TA_TOKEN, t2.TA_TOKEN order by count(*) desc'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create view\n",
    "# all adjective-noun bigrams with ID < 1000000 and w1=* and w2=not_Tire\n",
    "sql = 'create view adjective_noun_bigram_not_tire as select t1.TA_TOKEN as adjective, t2.TA_TOKEN as noun, count(*) as  w1_and_not_w2 from \"SYSTEM\".\"$TA_CDESCRIND\" as t1, \"SYSTEM\".\"$TA_CDESCRIND\" as t2 where t1.cmplid=t2.cmplid and t1.TA_COUNTER=t2.TA_COUNTER-1 and t1.TA_SENTENCE=t2.TA_SENTENCE and t1.TA_TYPE=\\'adjective\\' and t2.TA_TYPE=\\'noun\\' and t1.cmplid<1000000 and t2.TA_TOKEN!=\\'TIRE\\' group by t1.TA_TOKEN, t2.TA_TOKEN order by count(*) desc'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-Views\n",
    "sql_drop_view = 'drop view <view_name>'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "select adjective, noun, o11, o12, o21, o22 from \n",
    "(\n",
    "select t1.adjective, t1.noun, w1_and_w2 as o11, (sum_w1_and_w2-SUM(w1_and_w2)) as o12, t3.sum_w1_and_not_w2 as o21, (sum_NOT_w2 - t3.sum_w1_and_not_w2) as o22 from \n",
    "\"SYSTEM\".\"ADJECTIVE_NOUN_BIGRAM\" as t1, \n",
    "(select SUM(w1_and_w2) as sum_w1_and_w2 from \"SYSTEM\".\"ADJECTIVE_NOUN_BIGRAM\") as t2,\n",
    "(select adjective, SUM(w1_and_not_w2) as sum_w1_and_not_w2 from \"SYSTEM\".\"ADJECTIVE_NOUN_BIGRAM_NOT_TIRE\" group by adjective) as t3,\n",
    "(select SUM(w1_and_not_w2) as sum_NOT_w2 from \"SYSTEM\".\"ADJECTIVE_NOUN_BIGRAM_NOT_TIRE\" order by sum_NOT_w2 desc) as t4 where t3.adjective=t1.adjective group by t1.adjective, t1.noun, w1_and_w2, t2.sum_w1_and_w2, t3.sum_w1_and_not_w2, t4.sum_NOT_w2\n",
    ")\n",
    "\"\"\");\n",
    "data = cursor.fetchall();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_list = []\n",
    "header = [\"adjective\", \"noun\", \"o11\", \"o12\", \"o21\", \"o22\", \"chi_square\"];\n",
    "for item in data:\n",
    "    o11=item[2]\n",
    "    o12=item[3]\n",
    "    o21= item[4]\n",
    "    o22=item[5]\n",
    "    chi_square = ((102848 * (o11 * o22 - o12 * o21)**2) / ((o11 + o12) * (o11 + o21) * (o12 + o22) * (o21 + o22)))\n",
    "    values_list.append((item[0], item[1], item[2], item[3], item[4], item[5], chi_square))\n",
    "\n",
    "values_list.sort(key=lambda x: x[6], reverse=True);\n",
    "df = pd.DataFrame(values_list)\n",
    "df.columns = [header]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implementieren Sie eine Ähnlichkeitsanfrage, die für einen gegebenen Anfragevektor (egal ob existierendes Dokument oder eigene Suchanfrage) die gerankten top n Dokumente anhand der Wortvektoren (nur Nomen ohne IDF-Gewichtung!) zurückgibt mit Hilfe von \n",
    "## a. Skalarprodukt (nnn nach SMART Notation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scalar_product(id):\n",
    "    sql = 'SELECT CMPLID, sum(PROD) AS SCALARPRODUCT FROM (SELECT a.CMPLID, a.WORD, a.TERM * b.CountReq AS PROD FROM TERMS_NHTSA AS a, (SELECT TA_TOKEN, count(*) AS CountReq FROM \"SYSTEM\".\"$TA_CDESCRIND\" WHERE CMPLID = '+id+' GROUP BY TA_TOKEN) AS b WHERE a.WORD = b.TA_TOKEN) GROUP BY CMPLID ORDER BY SCALARPRODUCT desc LIMIT 10;'\n",
    "    cursor.execute(sql)\n",
    "    idf = cursor.fetchall()\n",
    "    idf_df = pd.DataFrame(idf)\n",
    "    print(idf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create view TERMS_NHTSA\n",
    "sql = 'create view TERMS_NHTSA as SELECT CMPLID, TA_TOKEN AS WORD, count(*) AS TERM, POWER(count(*),2) AS TERMSQR FROM \"SYSTEM\".\"$TA_CDESCRIND\" WHERE TA_TYPE=\\'noun\\' GROUP BY CMPLID, TA_TOKEN'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-View\n",
    "sql_drop_view = 'drop view TERMS_NHTSA'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Kosinus Ähnlichkeit (nnc nach SMART Notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cosinus(id):\n",
    "    sql = 'SELECT CMPLID, SCALARPRODUCT / (Cos * (SELECT SQRT(sum(coutsqr)) FROM (SELECT TA_TOKEN, POWER(count(*),2) AS coutsqr FROM \"SYSTEM\".\"$TA_CDESCRIND\" WHERE CMPLID = '+id+' AND TA_TYPE = \\'noun\\' GROUP BY TA_TOKEN))) AS COSINUS FROM COS_NHTSA ORDER BY COSINUS DESC LIMIT 10'\n",
    "    cursor.execute(sql)\n",
    "    idf = cursor.fetchall()\n",
    "    idf_df = pd.DataFrame(idf)\n",
    "    print(idf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create view COS_NHTSA\n",
    "sql = 'create view COS_NHTSA as SELECT x.CMPLID AS CMPLID, x.SCALARPRODUCT AS SCALARPRODUCT, y.Cos AS Cos From (SELECT CMPLID, sum(PROD) AS SCALARPRODUCT FROM (SELECT a.CMPLID, a.WORD, a.TERM * b.CountReq AS PROD FROM TERMS_NHTSA AS a, (SELECT TA_TOKEN, count(*) AS CountReq FROM \"SYSTEM\".\"$TA_CDESCRIND\" WHERE CMPLID = 119408 GROUP BY TA_TOKEN) AS b WHERE a.WORD = b.TA_TOKEN) GROUP BY CMPLID) AS x, (SELECT CMPLID, SQRT(SUM(TERMSQR)) AS Cos FROM TERMS_NHTSA GROUP BY CMPLID) AS y WHERE x.CMPLID = y.CMPLID'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-View\n",
    "sql_drop_view = 'drop view COS_NHTSA'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Welches sind die jeweils ähnlichsten Dokumente für Complaint 119408? Wie unterscheiden sich die Ergebnisse grundsätzlich?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scalar_product('119408');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosinus('119408');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.  Aufgaben 1-6 auf den eigenen Datensatz (T3N-Daten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Ermitteln Sie die häufigsten Folgen von Adjektiv-Nomen Bigrammen im Corpus (Hinweis: wenn Sie mit SQL arbeiten, können Sie einen non-equi auto-join verwenden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select top 10 t1.TA_TOKEN, t2.TA_TOKEN, count(*) from \"SYSTEM\".\"$TA_T3NTEXTIND\" as t1, \"SYSTEM\".\"$TA_T3NTEXTIND\" as t2 where t1.ID=t2.ID and t1.TA_COUNTER=t2.TA_COUNTER-1 and t1.TA_SENTENCE=t2.TA_SENTENCE and t1.TA_TYPE=\\'adjective\\' and t2.TA_TYPE=\\'noun\\' group by t1.TA_TOKEN, t2.TA_TOKEN order by count(*) desc'\n",
    "cursor.execute(sql)\n",
    "adjective_noun = cursor.fetchall()\n",
    "adjective_noun_df = pd.DataFrame(adjective_noun)\n",
    "adjective_noun_df.columns = ['adjective', 'noun', 'count']\n",
    "adjective_noun_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ermitteln Sie die häufigsten Co-occurrences von Adjektiven innerhalb eines Satzes (Position egal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select top 10 t1.TA_TOKEN as adjective, t2.TA_TOKEN as adjective2, count(*) from \"SYSTEM\".\"$TA_T3NTEXTIND\" as t1, \"SYSTEM\".\"$TA_T3NTEXTIND\" as t2 where t1.ID=t2.ID and t1.TA_COUNTER<t2.TA_COUNTER and t1.TA_SENTENCE=t2.TA_SENTENCE and t1.TA_TYPE=\\'adjective\\' and t2.TA_TYPE=\\'adjective\\' group by t1.TA_TOKEN, t2.TA_TOKEN order by count(*) desc'\n",
    "cursor.execute(sql)\n",
    "adj_adj = cursor.fetchall()\n",
    "adj_adj_df = pd.DataFrame(adj_adj)\n",
    "adj_adj_df.columns = ['adjective', 'adjective 2', 'count']\n",
    "adj_adj_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3n_df = pd.read_csv('../praktikum2/t3n_data_cleaned.csv')\n",
    "t3n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3n_adjectives = t3n_df[t3n_df['TA_TYPE']=='adjective']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_coocurrencies = t3n_adjectives.groupby(['ID','TA_SENTENCE'])['TA_TOKEN_LOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coocurrencies = {}\n",
    "\n",
    "#generate \"matrix\" with coocurrencies. we count the coocurrencies of each adverb per sentence. \n",
    "for name, group in grouped_coocurrencies:\n",
    "    for index_i, token_i in group.iteritems():\n",
    "        type(token_i)\n",
    "        if token_i not in coocurrencies:\n",
    "            coocurrencies[token_i] = {}\n",
    "            \n",
    "        for index_j, token_j in group.iteritems():\n",
    "            if token_j not in coocurrencies[token_i]:\n",
    "                coocurrencies[token_i][token_j] = 0\n",
    "            else:\n",
    "                coocurrencies[token_i][token_j]+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_coocurrencies = {}\n",
    "\n",
    "for coocurrency in coocurrencies:\n",
    "    coocurrencies_for_this_token = coocurrencies[coocurrency]\n",
    "    for coocurrency_for_this_token in coocurrencies_for_this_token:\n",
    "        if(coocurrency != coocurrency_for_this_token):\n",
    "            ordered_coocurrencies[coocurrency + '-' + coocurrency_for_this_token] = coocurrencies_for_this_token[coocurrency_for_this_token] \n",
    "            \n",
    "ordered_coocurrencies = {k: v for k, v in sorted(ordered_coocurrencies.items(), key=lambda item: item[1],reverse=True)}        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dublicates(ordered_coocurrencies):\n",
    "    for occurency in ordered_coocurrencies.copy():\n",
    "        split_occurency = occurency.split('-')\n",
    "        dublicate_occurency = split_occurency[1] + '-' + split_occurency[0]\n",
    "        if dublicate_occurency in ordered_coocurrencies and occurency in ordered_coocurrencies:\n",
    "            ordered_coocurrencies.pop(dublicate_occurency)\n",
    "    return ordered_coocurrencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_dublicates(ordered_coocurrencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Berechnen Sie die top-3 tf-idf (ntn nach der SMART Notation) Werte von Nomen im Corpus. Schauen Sie sich die entsprechenden Dokumente und die jeweiligen tf bzw. idf Wertkomponenten an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL-View MAX_FREQ_NOUN_T3N\n",
    "sql = 'create view MAX_FREQ_NOUN_T3N as select ID as ID, TA_TOKEN as noun, count(*) as tf from \"$TA_T3NTEXTIND\" where TA_TYPE=\\'noun\\' group by ID, TA_TOKEN order by count(*) desc'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-View MAX_FREQ_NOUN_T3N\n",
    "sql_drop_view = 'drop view MAX_FREQ_NOUN_T3N'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf\n",
    "sql = 'select top 3 ID, noun, tf from MAX_FREQ_NOUN_T3N'\n",
    "cursor.execute(sql)\n",
    "tf = cursor.fetchall()\n",
    "tf_df = pd.DataFrame(tf)\n",
    "tf_df.columns = ['ID','noun', 'tf']\n",
    "tf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL-View COUNT_DOCS_T3N\n",
    "sql = 'create view COUNT_DOCS_T3N as select count(DISTINCT id) as n_total from \"$TA_T3NTEXTIND\"'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL-View VALUES_DF_T3N\n",
    "sql = 'create view VALUES_DF_T3N as select TA_TOKEN as noun, count(DISTINCT ID) as DF from \"$TA_T3NTEXTIND\" where TA_TYPE=\\'noun\\' group by TA_TOKEN'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL-View VALUES_IDF_T3N\n",
    "sql = 'create view VALUES_IDF_T3N as select t1.noun, ln((t2.n_total/t1.DF)) as idf from VALUES_DF_T3N as t1, COUNT_DOCS_T3N as t2 order by idf desc' \n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-Views\n",
    "sql_drop_view = 'drop view VALUES_IDF_T3N'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idf\n",
    "sql = 'select top 3 * from VALUES_IDF_T3N'\n",
    "cursor.execute(sql)\n",
    "idf = cursor.fetchall()\n",
    "idf_df = pd.DataFrame(idf)\n",
    "idf_df.columns = ['noun', 'idf']\n",
    "idf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select top 3 t2.ID, t1.noun, t2.tf, t1.idf, (t2.tf*t1.idf) as tfidf from VALUES_IDF_T3N as t1, MAX_FREQ_NOUN_T3N as t2 where t1.noun = t2.noun order by tfidf desc'\n",
    "cursor.execute(sql)\n",
    "idf = cursor.fetchall()\n",
    "idf_df = pd.DataFrame(idf)\n",
    "idf_df.columns = ['ID', 'noun','tf', 'idf', 'tfidf']\n",
    "idf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Berücksichtigen Sie alle Adjektiv-Nomen Bigramme in Dokumenten. Ermitteln Sie anhand des Chi2 Tests die 3 statistisch signifikantesten und die 3 am wenigsten signifikant zusammenhängenden Bigramme mit w1=* (beliebig) und w2=Text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create view\n",
    "# all adjective-noun bigrams and w1=* and w2=Text\n",
    "sql = 'create view adjective_noun_bigram_T3N as select t1.TA_TOKEN as adjective, t2.TA_TOKEN as noun, count(*) as  w1_and_w2 from \"SYSTEM\".\"$TA_T3NTEXTIND\" as t1, \"SYSTEM\".\"$TA_T3NTEXTIND\" as t2 where t1.ID=t2.ID and t1.TA_COUNTER=t2.TA_COUNTER-1 and t1.TA_SENTENCE=t2.TA_SENTENCE and t1.TA_TYPE=\\'adjective\\' and t2.TA_TYPE=\\'noun\\' and t2.TA_TOKEN=\\'Text\\' group by t1.TA_TOKEN, t2.TA_TOKEN order by count(*) desc'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create view\n",
    "# all adjective-noun bigrams and w1=* and w2=not_Text\n",
    "sql = 'create view adjective_noun_bigram_not_text as select t1.TA_TOKEN as adjective, t2.TA_TOKEN as noun, count(*) as  w1_and_not_w2 from \"SYSTEM\".\"$TA_T3NTEXTIND\" as t1, \"SYSTEM\".\"$TA_T3NTEXTIND\" as t2 where t1.ID=t2.ID and t1.TA_COUNTER=t2.TA_COUNTER-1 and t1.TA_SENTENCE=t2.TA_SENTENCE and t1.TA_TYPE=\\'adjective\\' and t2.TA_TYPE=\\'noun\\' and t2.TA_TOKEN!=\\'Text\\' group by t1.TA_TOKEN, t2.TA_TOKEN order by count(*) desc'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-Views\n",
    "sql_drop_view = 'drop view adjective_noun_bigram_T3N'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "select adjective, noun, o11, o12, o21, o22 from \n",
    "(\n",
    "select t1.adjective, t1.noun, w1_and_w2 as o11, (sum_w1_and_w2-SUM(w1_and_w2)) as o12, t3.sum_w1_and_not_w2 as o21, (sum_NOT_w2 - t3.sum_w1_and_not_w2) as o22 from \n",
    "\"SYSTEM\".\"ADJECTIVE_NOUN_BIGRAM_T3N\" as t1, \n",
    "(select SUM(w1_and_w2) as sum_w1_and_w2 from \"SYSTEM\".\"ADJECTIVE_NOUN_BIGRAM_T3N\") as t2,\n",
    "(select adjective, SUM(w1_and_not_w2) as sum_w1_and_not_w2 from \"SYSTEM\".\"ADJECTIVE_NOUN_BIGRAM_NOT_TEXT\" group by adjective) as t3,\n",
    "(select SUM(w1_and_not_w2) as sum_NOT_w2 from \"SYSTEM\".\"ADJECTIVE_NOUN_BIGRAM_NOT_TEXT\" order by sum_NOT_w2 desc) as t4 where t3.adjective=t1.adjective group by t1.adjective, t1.noun, w1_and_w2, t2.sum_w1_and_w2, t3.sum_w1_and_not_w2, t4.sum_NOT_w2\n",
    ")\n",
    "\"\"\");\n",
    "data = cursor.fetchall();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_list = []\n",
    "header = [\"adjective\", \"noun\", \"o11\", \"o12\", \"o21\", \"o22\", \"chi_square\"];\n",
    "for item in data:\n",
    "    o11=item[2]\n",
    "    o12=item[3]\n",
    "    o21= item[4]\n",
    "    o22=item[5]\n",
    "    chi_square = ((102848 * (o11 * o22 - o12 * o21)**2) / ((o11 + o12) * (o11 + o21) * (o12 + o22) * (o21 + o22)))\n",
    "    values_list.append((item[0], item[1], item[2], item[3], item[4], item[5], chi_square))\n",
    "\n",
    "values_list.sort(key=lambda x: x[6], reverse=True);\n",
    "df = pd.DataFrame(values_list)\n",
    "df.columns = [header]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Implementieren Sie eine Ähnlichkeitsanfrage, die für einen gegebenen Anfragevektor (egal ob existierendes Dokument oder eigene Suchanfrage) die gerankten top n Dokumente anhand der Wortvektoren (nur Nomen ohne IDF-Gewichtung!) zurückgibt mit Hilfe von \n",
    "#### a. Skalarprodukt (nnn nach SMART Notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_product(id):\n",
    "    sql = 'SELECT ID, sum(PROD) AS SCALARPRODUCT FROM (SELECT a.ID, a.WORD, a.TERM * b.CountReq AS PROD FROM TERMS_T3N AS a, (SELECT TA_TOKEN, count(*) AS CountReq FROM \"SYSTEM\".\"$TA_T3NTEXTIND\" WHERE ID = \\''+id+'\\' GROUP BY TA_TOKEN) AS b WHERE a.WORD = b.TA_TOKEN) GROUP BY ID ORDER BY SCALARPRODUCT desc LIMIT 10;'\n",
    "    cursor.execute(sql)\n",
    "    idf = cursor.fetchall()\n",
    "    idf_df = pd.DataFrame(idf)\n",
    "    print(idf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create view TERMS_T3N\n",
    "sql = 'create view TERMS_T3N as SELECT ID, TA_TOKEN AS WORD, count(*) AS TERM, POWER(count(*),2) AS TERMSQR FROM \"SYSTEM\".\"$TA_T3NTEXTIND\" WHERE TA_TYPE=\\'noun\\' GROUP BY ID, TA_TOKEN'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop SQL-View\n",
    "sql_drop_view = 'drop view TERMS_T3N'\n",
    "cursor.execute(sql_drop_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Kosinus Ähnlichkeit (nnc nach SMART Notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosinus(id):\n",
    "    # create view COS_T3N\n",
    "    sql = 'create view COS_T3N as SELECT x.ID AS ID, x.SCALARPRODUCT AS SCALARPRODUCT, y.Cos AS Cos From (SELECT ID, sum(PROD) AS SCALARPRODUCT FROM (SELECT a.ID, a.WORD, a.TERM * b.CountReq AS PROD FROM TERMS_T3N AS a, (SELECT TA_TOKEN, count(*) AS CountReq FROM \"SYSTEM\".\"$TA_T3NTEXTIND\" WHERE ID = \\''+id+'\\' GROUP BY TA_TOKEN) AS b WHERE a.WORD = b.TA_TOKEN) GROUP BY ID) AS x, (SELECT ID, SQRT(SUM(TERMSQR)) AS Cos FROM TERMS_T3N GROUP BY ID) AS y WHERE x.ID = y.ID'\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    sql = 'SELECT ID, SCALARPRODUCT / (Cos * (SELECT SQRT(sum(coutsqr)) FROM (SELECT TA_TOKEN, POWER(count(*),2) AS coutsqr FROM \"SYSTEM\".\"$TA_T3NTEXTIND\" WHERE ID = \\''+id+'\\' AND TA_TYPE = \\'noun\\' GROUP BY TA_TOKEN))) AS COSINUS FROM COS_T3N ORDER BY COSINUS DESC LIMIT 10'\n",
    "    cursor.execute(sql)\n",
    "    idf = cursor.fetchall()\n",
    "    idf_df = pd.DataFrame(idf)\n",
    "    \n",
    "    # drop SQL-View\n",
    "    sql_drop_view = 'drop view COS_T3N'\n",
    "    cursor.execute(sql_drop_view)\n",
    "    \n",
    "    print(idf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Welches sind die jeweils ähnlichsten Dokumente für das Dokument mit der ID 54ff8c69-007f-49a8-94cf-093fb5b0951b? Wie unterscheiden sich die Ergebnisse grundsätzlich?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_product('54ff8c69-007f-49a8-94cf-093fb5b0951b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosinus('54ff8c69-007f-49a8-94cf-093fb5b0951b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 2\n",
    "## 1. Implementieren oder wrappen Sie eine Python-Funktion (gerne mit Hilfe üblicher Bibliotheken wie sklearn.metrics.precision_recall_curve), die für Ihre vorbereiteten Anfragevektoren und die mit der Kosinus-Ähnlichkeit ermittelten Dokumente die Precision-Recall Plots zeichnet (Interpolation ist nicht nötig)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t3n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_t3n = pd.DataFrame(columns=['Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precisionRecall_t3n(param, row_number):\n",
    "    gefunden_sql = 'SELECT distinct ID FROM \"SYSTEM\".\"$TA_T3NTEXTIND\" WHERE TA_TOKEN = ('+param+')'    \n",
    "    cursor.execute(gefunden_sql)\n",
    "    gefunden_list = cursor.fetchall()\n",
    "    \n",
    "    relevant_sql = 'SELECT distinct ID FROM \"SYSTEM\".\"T3N\" where CATEGORY = \\'Marketing\\' '\n",
    "    cursor.execute(relevant_sql)\n",
    "    relevant_list = cursor.fetchall()\n",
    "    \n",
    "    schnitt = 'SELECT * FROM ('+relevant_sql+') as t1, ('+gefunden_sql+') as t2 where t1.ID = t2.ID'\n",
    "    cursor.execute(schnitt)\n",
    "    schnitt_list = cursor.fetchall()\n",
    "    \n",
    "    recall = abs((len(schnitt_list)) / len(relevant_list))\n",
    "    precision = abs((len(schnitt_list)) / len(gefunden_list))\n",
    "\n",
    "    results_t3n.loc[row_number,'Precision'] = precision\n",
    "    results_t3n.loc[row_number,'Recall'] = recall\n",
    "    \n",
    "    print(f\"Recall: {recall} \")\n",
    "    print(f\"Precision: {precision} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Amazon\")\n",
    "precisionRecall_t3n('\\'Amazon\\'', 0)\n",
    "print(\"Microsoft\")\n",
    "precisionRecall_t3n('\\'Microsoft\\'', 1)\n",
    "print(\"Google\")\n",
    "precisionRecall_t3n('\\'Google\\'', 2)\n",
    "print(\"Apple\")\n",
    "precisionRecall_t3n('\\'Apple\\'', 3)\n",
    "print(\"Facebook\")\n",
    "precisionRecall_t3n('\\'Facebook\\'', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Recall', y='Precision', data=results_t3n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NHTSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def precisionRecall(param, row_number):\n",
    "    gefunden_sql = 'SELECT distinct CMPLID FROM \"SYSTEM\".\"$TA_CDESCRIND\" WHERE TA_TOKEN = ('+param+')'    \n",
    "    cursor.execute(gefunden_sql)\n",
    "    gefunden_list = cursor.fetchall()\n",
    "    \n",
    "    relevant_sql = 'SELECT distinct CMPLID FROM \"SYSTEM\".\"CMPL100K\" where COMPDESC = \\'AIR BAGS\\' '\n",
    "    cursor.execute(relevant_sql)\n",
    "    relevant_list = cursor.fetchall()\n",
    "    \n",
    "    schnitt = 'SELECT * FROM ('+relevant_sql+') as t1, ('+gefunden_sql+') as t2 where t1.CMPLID = t2.CMPLID'\n",
    "    cursor.execute(schnitt)\n",
    "    schnitt_list = cursor.fetchall()\n",
    "    \n",
    "    recall = abs((len(schnitt_list)) / len(relevant_list))\n",
    "    precision = abs((len(schnitt_list)) / len(gefunden_list))\n",
    "    \n",
    "    results.loc[row_number,'Precision'] = precision\n",
    "    results.loc[row_number,'Recall'] = recall\n",
    "\n",
    "    print(f\"Recall: {recall} \")\n",
    "    print(f\"Precision: {precision} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AIR\")\n",
    "precisionRecall('\\'AIR\\'', 0)\n",
    "print(\"BAG\")\n",
    "precisionRecall('\\'BAG\\'', 1)\n",
    "print(\"ACCIDENT\")\n",
    "precisionRecall('\\'ACCIDENT\\'', 2)\n",
    "print(\"DEPLOYMENT\")\n",
    "precisionRecall('\\'DEPLOYMENT\\'', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Recall', y='Precision', data=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wie interpretieren Sie die Retrieval-Ergebnisse und die Plots (für Ihre eigenen Anfragen und mindestens für die Anfrage {'AIR': 2, 'BAG': 2, 'DEPLOYMENT':2, 'ACCIDENT':2} an NHTSA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
